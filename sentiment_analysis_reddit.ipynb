{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b5279a-1db5-41a7-a235-22dbd0782997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0b21d2-90d8-40b8-8d5c-0fe693b88e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75c36d2-1c6a-4c8a-93fb-5d8fe8bdc131",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File reddit_data.json.gz does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# filenames = glob.glob('reddit-subset2\\submissions\\part-*.json.gz')\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# ind_df = (pd.read_json(f, lines=True) for f in filenames)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# df = pd.concat(ind_df, ignore_index=True)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreddit_data.json.gz\u001b[39m\u001b[38;5;124m'\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselftext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[removed]\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselftext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[deleted]\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubreddit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuebec\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/json/_json.py:780\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    778\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 780\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m JsonReader(\n\u001b[1;32m    781\u001b[0m     path_or_buf,\n\u001b[1;32m    782\u001b[0m     orient\u001b[38;5;241m=\u001b[39morient,\n\u001b[1;32m    783\u001b[0m     typ\u001b[38;5;241m=\u001b[39mtyp,\n\u001b[1;32m    784\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    785\u001b[0m     convert_axes\u001b[38;5;241m=\u001b[39mconvert_axes,\n\u001b[1;32m    786\u001b[0m     convert_dates\u001b[38;5;241m=\u001b[39mconvert_dates,\n\u001b[1;32m    787\u001b[0m     keep_default_dates\u001b[38;5;241m=\u001b[39mkeep_default_dates,\n\u001b[1;32m    788\u001b[0m     precise_float\u001b[38;5;241m=\u001b[39mprecise_float,\n\u001b[1;32m    789\u001b[0m     date_unit\u001b[38;5;241m=\u001b[39mdate_unit,\n\u001b[1;32m    790\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    791\u001b[0m     lines\u001b[38;5;241m=\u001b[39mlines,\n\u001b[1;32m    792\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    793\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    794\u001b[0m     nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[1;32m    795\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    796\u001b[0m     encoding_errors\u001b[38;5;241m=\u001b[39mencoding_errors,\n\u001b[1;32m    797\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    798\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    799\u001b[0m )\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/json/_json.py:893\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 893\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data_from_filepath(filepath_or_buffer)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/json/_json.py:949\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    941\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    948\u001b[0m ):\n\u001b[0;32m--> 949\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    951\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    957\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File reddit_data.json.gz does not exist"
     ]
    }
   ],
   "source": [
    "# filenames = glob.glob('reddit-subset2\\submissions\\part-*.json.gz')\n",
    "# ind_df = (pd.read_json(f, lines=True) for f in filenames)\n",
    "# df = pd.concat(ind_df, ignore_index=True)\n",
    "df = pd.read_json('reddit_data.json.gz', lines=True)\n",
    "df = df[(df['selftext'] != '[removed]') & (df['selftext'] != '[deleted]') & (df['subreddit'] != 'Quebec')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c38923-c8f7-4f69-b91f-6c088951b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(input):\n",
    "    scores = sia.polarity_scores(input)\n",
    "    return scores['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957fb1d-d214-4a26-bf18-57622274afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores = np.vectorize(get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e875c-da47-4532-ac62-22d38221da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = get_scores(df['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5f1d9-55d0-4d79-824f-7de7735a5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_annual = df.groupby(['subreddit', 'year']).agg({'score': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3967993-4bff-4b78-bec6-83e3a1d97529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_annual.to_csv('sentiment_score_annual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b53491-ee75-43d7-8d40-d338eb0300dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_quarterly = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebb645-eaad-421b-b211-fd7c32d39254",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_quarterly['date'] = pd.to_datetime(df['year'].astype(str) + df['month'].astype(str), format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf056c0-fa29-4abd-8a10-676179859d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_quarterly = sentiment_score_quarterly.groupby(['subreddit', sentiment_score_quarterly['date'].dt.to_period('Q')]).agg({'score': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14116150-8ab2-4ce8-a10b-ef3452032800",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_quarterly.to_csv('sentiment_score_quarterly.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
